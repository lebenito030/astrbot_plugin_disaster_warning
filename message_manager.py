"""
æ¶ˆæ¯æ¨é€ç®¡ç†å™¨
"""

import urllib.parse
from collections import defaultdict
from datetime import datetime, timedelta
from typing import Any

import astrbot.api.message_components as Comp
from astrbot.api import logger
from astrbot.api.event import MessageChain

from .event_deduplicator import EventDeduplicator
from .models import (
    DataSource,
    DisasterEvent,
    EarthquakeData,
    TsunamiData,
    WeatherAlarmData,
)


class MessagePushManager:
    """æ¶ˆæ¯æ¨é€ç®¡ç†å™¨"""

    def __init__(self, config: dict[str, Any], context):
        self.config = config
        self.context = context

        # åˆå§‹åŒ–äº‹ä»¶å»é‡å™¨
        self.deduplicator = EventDeduplicator(
            time_window_minutes=1, location_tolerance_km=20.0, magnitude_tolerance=0.5
        )

        # äº‹ä»¶æ¨é€è®°å½•
        self.event_push_records: dict[str, list[dict]] = defaultdict(list)

        # æœ€ç»ˆæŠ¥è®°å½•
        self.final_reports: set[str] = set()

        # æ¨é€é¢‘ç‡æ§åˆ¶é…ç½®
        self.push_every_n_reports = config.get("push_frequency_control", {}).get(
            "push_every_n_reports", 1
        )
        self.final_report_always_push = config.get("push_frequency_control", {}).get(
            "final_report_always_push", True
        )
        self.ignore_non_final_reports = config.get("push_frequency_control", {}).get(
            "ignore_non_final_reports", False
        )
        self.first_report_always_push = config.get("push_frequency_control", {}).get(
            "first_report_always_push", True
        )  # æ–°å¢ï¼šç¡®ä¿ç¬¬1æŠ¥æ€»æ˜¯è¢«æ¨é€

        # é˜ˆå€¼é…ç½®
        self.thresholds = config.get("earthquake_thresholds", {})

        # çœä»½ç™½åå•é…ç½®ï¼ˆåˆ†ä¸ºåœ°éœ‡/æµ·å•¸å’Œæ°”è±¡ä¸¤ç§ï¼‰
        self.earthquake_province_whitelist = config.get("earthquake_province_whitelist", [])
        self.weather_province_whitelist = config.get("weather_province_whitelist", [])
        # ç™½åå•ä¸ºç©ºæ—¶æ˜¯å¦åŒ…å«å›½å¤–äº‹ä»¶çš„å¼€å…³
        self.earthquake_whitelist_include_international = config.get("earthquake_whitelist_include_international", False)
        self.weather_whitelist_include_international = config.get("weather_whitelist_include_international", False)

        # ç›®æ ‡ä¼šè¯
        self.target_sessions = self._parse_target_sessions()

        # åœ°å›¾é…ç½®
        self.include_map = config.get("message_format", {}).get("include_map", True)
        self.map_provider = config.get("message_format", {}).get(
            "map_provider", "openstreetmap"
        )
        self.map_zoom_level = config.get("message_format", {}).get("map_zoom_level", 5)

    def _parse_target_sessions(self) -> list[str]:
        """è§£æç›®æ ‡ä¼šè¯"""
        target_groups = self.config.get("target_groups", [])
        sessions = []

        for group_id in target_groups:
            if group_id:
                # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„ä¼šè¯IDæ ¼å¼ï¼ŒåŠ¨æ€è·å–å¹³å°å
                platform_name = self._get_platform_name_for_group(group_id)
                session = f"{platform_name}:GroupMessage:{group_id}"
                sessions.append(session)

        return sessions

    def _get_platform_name_for_group(self, group_id: str) -> str:
        """ä¸ºç¾¤ç»„è·å–å¹³å°å - ä»é…ç½®è¯»å–ï¼Œæ”¯æŒå†å²å­¦ä¹ """
        # æ–¹æ³•1ï¼šä»é…ç½®ä¸­è¯»å–ç”¨æˆ·æŒ‡å®šçš„å¹³å°å
        config_platform = self.config.get("platform_name", "default")
        if config_platform and config_platform != "default":
            return config_platform

        # æ–¹æ³•2ï¼šä»æ¨é€å†å²ä¸­å­¦ä¹ ï¼ˆå¦‚æœä¹‹å‰æœ‰æˆåŠŸæ¨é€çš„ä¼šè¯ï¼‰
        for session_id in self.event_push_records.keys():
            if session_id.endswith(f":GroupMessage:{group_id}"):
                # æå–å¹³å°åï¼ˆä¼šè¯IDæ ¼å¼ï¼šplatform:GroupMessage:group_idï¼‰
                parts = session_id.split(":")
                if len(parts) >= 3:
                    return parts[0]

        # æ–¹æ³•3ï¼šä»æœ€ç»ˆæŠ¥è®°å½•ä¸­æå–
        for session_id in self.final_reports:
            if session_id.endswith(f":GroupMessage:{group_id}"):
                parts = session_id.split(":")
                if len(parts) >= 3:
                    return parts[0]

        # æ–¹æ³•4ï¼šä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼ï¼ˆé¦–æ¬¡æ¨é€æ—¶ä½¿ç”¨ï¼‰
        default_platform = config_platform or "default"
        logger.debug(f"[ç¾å®³é¢„è­¦] ä½¿ç”¨å¹³å°å '{default_platform}' ç”¨äºç¾¤ç»„ {group_id}")
        return default_platform

    def should_push_event(self, event: DisasterEvent) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ¨é€äº‹ä»¶ - è¯¦ç»†çš„è¿‡æ»¤é€»è¾‘åˆ¤æ–­"""
        event_id = self._get_event_id(event)

        # ç»Ÿä¸€çš„äº‹ä»¶è¿‡æ»¤æ—¥å¿—è®°å½•
        filter_reasons = []

        # ğŸ”¥ ä¿®å¤ï¼šå°†æ—¶é—´æ£€æŸ¥æ”¾åœ¨æœ€å‰é¢ï¼Œç¡®ä¿ä¸ä¼šè¢«ç»•è¿‡
        # æ£€æŸ¥äº‹ä»¶æ—¶é—´æ˜¯å¦è¿‡æ—¶ï¼ˆè¶…è¿‡1å°æ—¶ï¼‰- æ‰©å±•åˆ°æ‰€æœ‰ç¾å®³ç±»å‹
        event_time = self._get_event_time(event)
        if event_time:
            time_diff = (datetime.now() - event_time).total_seconds() / 3600  # å°æ—¶
            logger.debug(
                f"[ç¾å®³é¢„è­¦] æ—¶é—´æ£€æŸ¥ - äº‹ä»¶ID: {event_id}, äº‹ä»¶æ—¶é—´: {event_time}, å½“å‰æ—¶é—´: {datetime.now()}, æ—¶é—´å·®: {time_diff:.1f}å°æ—¶"
            )
            if time_diff > 1:
                logger.info(
                    f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æ—¶é—´è¿‡æ—©ï¼ˆ{time_diff:.1f}å°æ—¶å‰ï¼‰"
                )
                return False
        else:
            logger.warning(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æ—¶é—´ä¿¡æ¯ç¼ºå¤±ï¼Œç»§ç»­å…¶ä»–æ£€æŸ¥")

        # çœä»½ç™½åå•è¿‡æ»¤
        if not self._check_province_whitelist(event):
            logger.info(
                f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æœªé€šè¿‡çœä»½ç™½åå•æ£€æŸ¥"
            )
            return False

        # æ£€æŸ¥é˜ˆå€¼
        if not self._check_thresholds(event):
            filter_reasons.append("æœªé€šè¿‡é˜ˆå€¼æ£€æŸ¥")

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆæŠ¥
        is_final = self._is_final_report(event)
        if is_final:
            # æœ€ç»ˆæŠ¥æ€»æ˜¯æ¨é€ï¼Œä½†éœ€è¦æ£€æŸ¥æ—¶é—´é™åˆ¶
            if self.final_report_always_push:
                # ğŸ”¥ ä¿®å¤ï¼šæœ€ç»ˆæŠ¥ä¹Ÿéœ€è¦æ£€æŸ¥æ—¶é—´ï¼Œä¸èƒ½ç»•è¿‡æ—¶é—´é™åˆ¶
                event_time = self._get_event_time(event)
                if event_time:
                    time_diff = (datetime.now() - event_time).total_seconds() / 3600
                    if time_diff > 1:
                        logger.info(
                            f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} è™½ç„¶æ˜¯æœ€ç»ˆæŠ¥ï¼Œä½†æ—¶é—´è¿‡æ—©ï¼ˆ{time_diff:.1f}å°æ—¶å‰ï¼‰ï¼Œè¿‡æ»¤"
                        )
                        return False
                logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æ˜¯æœ€ç»ˆæŠ¥ï¼Œå…è®¸æ¨é€")
                return True

        # âœ… æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬1æŠ¥ï¼Œç¡®ä¿ç¬¬1æŠ¥æ€»æ˜¯è¢«æ¨é€
        is_first_report = self._is_first_report(event)
        if is_first_report:
            if self.first_report_always_push:
                # ğŸ”¥ ä¿®å¤ï¼šç¬¬1æŠ¥ä¹Ÿéœ€è¦æ£€æŸ¥æ—¶é—´ï¼Œä¸èƒ½ç»•è¿‡æ—¶é—´é™åˆ¶
                event_time = self._get_event_time(event)
                if event_time:
                    time_diff = (datetime.now() - event_time).total_seconds() / 3600
                    if time_diff > 1:
                        logger.info(
                            f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} è™½ç„¶æ˜¯ç¬¬1æŠ¥ï¼Œä½†æ—¶é—´è¿‡æ—©ï¼ˆ{time_diff:.1f}å°æ—¶å‰ï¼‰ï¼Œè¿‡æ»¤"
                        )
                        return False
                logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æ˜¯ç¬¬1æŠ¥ï¼Œå…è®¸æ¨é€")
                return True

        # æ£€æŸ¥æ˜¯å¦å·²ç»æ¨é€è¿‡æœ€ç»ˆæŠ¥
        if event_id in self.final_reports:
            filter_reasons.append("æœ€ç»ˆæŠ¥å·²æ¨é€è¿‡")

        # æ£€æŸ¥æ¨é€é¢‘ç‡æ§åˆ¶
        if self.ignore_non_final_reports and not is_final:
            filter_reasons.append("éæœ€ç»ˆæŠ¥è¢«å¿½ç•¥")

        # æ£€æŸ¥æŠ¥æ•°æ§åˆ¶
        push_records = self.event_push_records.get(event_id, [])
        current_report_count = len(push_records) + 1

        # âœ… ä¼˜åŒ–ï¼šç¬¬1æŠ¥å·²ç»åœ¨ä¸Šé¢å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œåªå¤„ç†åç»­æŠ¥æ•°æ§åˆ¶
        if current_report_count == 1:
            # ç¬¬1æŠ¥å·²ç»åœ¨ä¸Šé¢å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œä¸å†é‡å¤åˆ¤æ–­
            if not self.first_report_always_push:
                # å¦‚æœç¬¬1æŠ¥ä¸å¼ºåˆ¶æ¨é€ï¼Œåˆ™æ£€æŸ¥æŠ¥æ•°æ§åˆ¶
                if current_report_count % self.push_every_n_reports != 0:
                    filter_reasons.append(f"æŠ¥æ•°æ§åˆ¶(ç¬¬{current_report_count}æŠ¥)")
        elif current_report_count % self.push_every_n_reports != 0:
            filter_reasons.append(f"æŠ¥æ•°æ§åˆ¶(ç¬¬{current_report_count}æŠ¥)")

        # å¦‚æœæœ‰è¿‡æ»¤åŸå› ï¼Œè®°å½•å¹¶è¿”å›False
        if filter_reasons:
            filter_reason = ", ".join(filter_reasons)
            logger.info(
                f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} æœªé€šè¿‡æ¨é€æ¡ä»¶æ£€æŸ¥ - åŸå› : {filter_reason}"
            )
            return False

        logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event_id} é€šè¿‡æ‰€æœ‰æ¨é€æ¡ä»¶æ£€æŸ¥")
        return True

    def _get_event_time(self, event: DisasterEvent) -> datetime | None:
        """è·å–ç¾å®³äº‹ä»¶çš„æ—¶é—´ - æ”¯æŒæ‰€æœ‰ç¾å®³ç±»å‹"""
        if isinstance(event.data, EarthquakeData):
            return event.data.shock_time
        elif isinstance(event.data, TsunamiData):
            return event.data.issue_time
        elif isinstance(event.data, WeatherAlarmData):
            # æ°”è±¡é¢„è­¦ä¼˜å…ˆä½¿ç”¨ç”Ÿæ•ˆæ—¶é—´ï¼Œå…¶æ¬¡ä½¿ç”¨å‘å¸ƒæ—¶é—´
            return event.data.effective_time or event.data.issue_time
        return None

    def _get_event_id(self, event: DisasterEvent) -> str:
        """è·å–äº‹ä»¶ID"""
        if isinstance(event.data, EarthquakeData):
            return event.data.event_id or event.data.id
        elif isinstance(event.data, (TsunamiData, WeatherAlarmData)):
            return event.data.id
        return event.id

    def _is_first_report(self, event: DisasterEvent) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç¬¬1æŠ¥ - åŸºäºAPIæ–‡æ¡£çš„ç²¾ç¡®å®ç°"""
        if isinstance(event.data, EarthquakeData):
            earthquake = event.data

            # åŸºäºä¸åŒæ•°æ®æºçš„æŠ¥æ•°å­—æ®µåˆ¤æ–­ç¬¬1æŠ¥
            if earthquake.source == DataSource.P2P_EARTHQUAKE:
                # P2Påœ°éœ‡æƒ…å ±: åŸºäºissue.serialå­—æ®µåˆ¤æ–­ç¬¬1æŠ¥
                issue_info = earthquake.raw_data.get("issue", {})
                serial = issue_info.get("serial")
                if serial:
                    return serial == "1"
                # å¤‡ç”¨ï¼šåŸºäºupdateså­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                return (
                    earthquake.updates == 1 if hasattr(earthquake, "updates") else True
                )

            elif earthquake.source == DataSource.P2P_EEW:
                # P2Pç·Šæ€¥åœ°éœ‡é€Ÿå ±: åŸºäºissue.serialå­—æ®µ
                # ä»APIæ–‡æ¡£çœ‹ï¼Œserial=1è¡¨ç¤ºç¬¬1æŠ¥
                issue_info = earthquake.raw_data.get("issue", {})
                return issue_info.get("serial") == "1" if issue_info else True

            elif earthquake.source in [
                DataSource.FAN_STUDIO_CEA,
                DataSource.FAN_STUDIO_CWA,
            ]:
                # ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘/å°æ¹¾ä¸­å¤®æ°”è±¡ç½²: åŸºäºupdateså­—æ®µ
                # APIæ–‡æ¡£æ˜ç¡®è¯´æ˜ï¼šupdates=1è¡¨ç¤ºç¬¬1æŠ¥
                return earthquake.updates == 1

            elif earthquake.source in [
                DataSource.WOLFX_JMA_EEW,
                DataSource.WOLFX_CENC_EEW,
                DataSource.WOLFX_CWA_EEW,
            ]:
                # Wolfx EEW: åŸºäºSerialæˆ–ReportNumå­—æ®µ
                # JMA: Serialå­—æ®µï¼ŒCENC: ReportNumå­—æ®µ
                if earthquake.source == DataSource.WOLFX_JMA_EEW:
                    return earthquake.raw_data.get("Serial") == 1
                else:
                    return earthquake.raw_data.get("ReportNum") == 1

            elif earthquake.source == DataSource.FAN_STUDIO_CENC:
                # ä¸­å›½åœ°éœ‡å°ç½‘: æ­£å¼æµ‹å®šï¼Œé€šå¸¸åªæœ‰1æŠ¥ï¼Œæ— æ›´æ–°æœºåˆ¶
                # åŸºäºinfoTypeNameå­—æ®µåˆ¤æ–­
                info_type = earthquake.info_type or ""
                return "[æ­£å¼æµ‹å®š]" in info_type or "[è‡ªåŠ¨æµ‹å®š]" in info_type

            elif earthquake.source == DataSource.FAN_STUDIO_USGS:
                # USGS: åŸºäºreviewed/automaticçŠ¶æ€
                # é¦–æ¬¡å‘å¸ƒé€šå¸¸æ˜¯automaticï¼Œåç»­å¯èƒ½æ˜¯reviewed
                info_type = earthquake.info_type or ""
                return info_type.lower() == "automatic"

            else:
                # é»˜è®¤ï¼šåŸºäºupdateså­—æ®µï¼Œupdates=1æˆ–æ²¡æœ‰updateså­—æ®µè®¤ä¸ºæ˜¯ç¬¬1æŠ¥
                return earthquake.updates == 1 or not hasattr(earthquake, "updates")

        return False

    def _is_final_report(self, event: DisasterEvent) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ç»ˆæŠ¥ - åŸºäºAPIæ–‡æ¡£çš„å¢å¼ºå®ç°"""
        if isinstance(event.data, EarthquakeData):
            earthquake = event.data

            # æ–¹æ³•1ï¼šç›´æ¥æ£€æŸ¥is_finalå­—æ®µï¼ˆæœ€å¯é ï¼Œé€‚ç”¨äºæ”¯æŒçš„æ•°æ®æºï¼‰
            if earthquake.is_final:
                return True

            # æ–¹æ³•2ï¼šåŸºäºä¸åŒæ•°æ®æºçš„ç‰¹æ€§åˆ¤æ–­æœ€ç»ˆæŠ¥

            # P2Påœ°éœ‡æƒ…å ±: åŸºäºissue.serialå­—æ®µå’Œæ¶ˆæ¯ç‰¹å¾
            if earthquake.source == DataSource.P2P_EARTHQUAKE:
                issue_info = earthquake.raw_data.get("issue", {})
                serial = issue_info.get("serial")
                if serial:
                    # é€šå¸¸serialä¼šé€’å¢ï¼Œå¯ä»¥ç»“åˆå…¶ä»–ç‰¹å¾åˆ¤æ–­
                    # ä¾‹å¦‚ï¼šå¦‚æœéœ‡åº¦ä¿¡æ¯å®Œæ•´ä¸”serialè¾ƒå¤§ï¼Œå¯èƒ½æ˜¯æœ€ç»ˆæŠ¥
                    return (
                        int(serial) >= 5
                        and earthquake.scale is not None
                        and earthquake.raw_data.get("earthquake", {}).get(
                            "maxScale", -1
                        )
                        != -1
                    )

            # P2Pç·Šæ€¥åœ°éœ‡é€Ÿå ±: åŸºäºissue.serialå’ŒisFinalå­—æ®µ
            elif earthquake.source == DataSource.P2P_EEW:
                issue_info = earthquake.raw_data.get("issue", {})
                serial = issue_info.get("serial")
                # ç»“åˆserialå’Œæ˜¯å¦æœ‰å®Œæ•´çš„éœ‡åº¦ä¿¡æ¯
                if serial and int(serial) >= 3:
                    areas = earthquake.raw_data.get("areas", [])
                    if areas and all(
                        area.get("scaleTo") is not None for area in areas[:3]
                    ):
                        return True

            # ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘/å°æ¹¾ä¸­å¤®æ°”è±¡ç½²: åŸºäºupdateså­—æ®µ
            elif earthquake.source in [
                DataSource.FAN_STUDIO_CEA,
                DataSource.FAN_STUDIO_CWA,
            ]:
                # updateså­—æ®µè¡¨ç¤ºæ›´æ–°æ¬¡æ•°ï¼Œä½†éœ€è¦ç»“åˆæ—¶é—´çª—å£åˆ¤æ–­
                # å¦‚æœupdatesè¾ƒå¤§ä¸”é•¿æ—¶é—´æ— æ›´æ–°ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯æœ€ç»ˆæŠ¥
                if earthquake.updates >= 5:  # è‡³å°‘5æ¬¡æ›´æ–°åæ‰è€ƒè™‘æ˜¯æœ€ç»ˆæŠ¥
                    # è¿™é‡Œå¯ä»¥æ·»åŠ æ—¶é—´çª—å£åˆ¤æ–­é€»è¾‘
                    return True

            # Wolfx EEW: åŸºäºisFinalå­—æ®µæˆ–Serial/ReportNumå­—æ®µ
            elif earthquake.source in [
                DataSource.WOLFX_JMA_EEW,
                DataSource.WOLFX_CENC_EEW,
                DataSource.WOLFX_CWA_EEW,
            ]:
                # ä¼˜å…ˆä½¿ç”¨isFinalå­—æ®µ
                if earthquake.raw_data.get("isFinal") is True:
                    return True
                # å¤‡ç”¨ï¼šåŸºäºSerial/ReportNumåˆ¤æ–­
                if earthquake.source == DataSource.WOLFX_JMA_EEW:
                    serial = earthquake.raw_data.get("Serial")
                    return serial is not None and serial >= 3
                else:
                    report_num = earthquake.raw_data.get("ReportNum")
                    return report_num is not None and report_num >= 3

            # ä¸­å›½åœ°éœ‡å°ç½‘: æ­£å¼æµ‹å®šé€šå¸¸å°±æ˜¯æœ€ç»ˆæŠ¥
            elif earthquake.source == DataSource.FAN_STUDIO_CENC:
                info_type = earthquake.info_type or ""
                return "[æ­£å¼æµ‹å®š]" in info_type

            # USGS: reviewedçŠ¶æ€è¡¨ç¤ºäººå·¥å¤æ ¸ï¼Œé€šå¸¸æ˜¯æœ€ç»ˆæŠ¥
            elif earthquake.source == DataSource.FAN_STUDIO_USGS:
                info_type = earthquake.info_type or ""
                return info_type.lower() == "reviewed"

            # æ–¹æ³•3ï¼šåŸºäºæ—¶é—´çª—å£çš„å¯å‘å¼åˆ¤æ–­ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            # å¦‚æœäº‹ä»¶å·²ç»æŒç»­ä¸€æ®µæ—¶é—´ï¼ˆå¦‚30åˆ†é’Ÿï¼‰ä¸”æ²¡æœ‰æ›´æ–°ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯æœ€ç»ˆæŠ¥
            # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é€»è¾‘ï¼ŒåŸºäºäº‹ä»¶æ—¶é—´å’Œå½“å‰æ—¶é—´çš„å·®å€¼

        return False

    def _check_province_whitelist(self, event: DisasterEvent) -> bool:
        """æ£€æŸ¥çœä»½ç™½åå• - å¦‚æœé…ç½®äº†ç™½åå•ï¼Œåªæ¨é€ç™½åå•ä¸­çœä»½çš„æ¶ˆæ¯"""
        # æ ¹æ®äº‹ä»¶ç±»å‹é€‰æ‹©å¯¹åº”çš„ç™½åå•å’Œå¼€å…³
        if isinstance(event.data, WeatherAlarmData):
            whitelist = self.weather_province_whitelist
            include_international = self.weather_whitelist_include_international
            event_type = "æ°”è±¡é¢„è­¦"
        else:  # EarthquakeData å’Œ TsunamiData
            whitelist = self.earthquake_province_whitelist
            include_international = self.earthquake_whitelist_include_international
            event_type = "åœ°éœ‡/æµ·å•¸"
        
        # æå–çœä»½ä¿¡æ¯
        province = self._extract_province(event)
        
        # å¦‚æœæ— æ³•æå–çœä»½ä¿¡æ¯ï¼ˆå¯èƒ½æ˜¯å›½å¤–äº‹ä»¶ï¼‰
        if not province:
            # ç™½åå•ä¸ºç©ºæ—¶ï¼Œæ ¹æ®å¼€å…³å†³å®šæ˜¯å¦æ¨é€
            if not whitelist:
                if include_international:
                    logger.debug(
                        f"[ç¾å®³é¢„è­¦] {event_type}äº‹ä»¶ {event.id} æ— æ³•æå–çœä»½ä¿¡æ¯ï¼Œç™½åå•ä¸ºç©ºä¸”å·²å¼€å¯å›½é™…äº‹ä»¶ï¼Œé€šè¿‡æ£€æŸ¥"
                    )
                    return True
                else:
                    logger.info(
                        f"[ç¾å®³é¢„è­¦] {event_type}äº‹ä»¶ {event.id} æ— æ³•æå–çœä»½ä¿¡æ¯ï¼ˆå¯èƒ½æ˜¯å›½å¤–äº‹ä»¶ï¼‰ï¼Œç™½åå•ä¸ºç©ºä½†æœªå¼€å¯å›½é™…äº‹ä»¶ï¼Œè¿‡æ»¤"
                    )
                    return False
            # ç™½åå•ä¸ä¸ºç©ºæ—¶ï¼Œæ— æ³•æå–çœä»½çš„äº‹ä»¶ä¸€å¾‹è¿‡æ»¤
            else:
                logger.info(
                    f"[ç¾å®³é¢„è­¦] {event_type}äº‹ä»¶ {event.id} æ— æ³•æå–çœä»½ä¿¡æ¯ï¼Œç™½åå•å·²å¯ç”¨ï¼Œè¿‡æ»¤"
                )
                return False
        
        # å¦‚æœç™½åå•ä¸ºç©ºï¼Œé€šè¿‡çœä»½æ£€æŸ¥ï¼ˆæ¨é€æ‰€æœ‰å›½å†…äº‹ä»¶ï¼‰
        if not whitelist:
            logger.debug(
                f"[ç¾å®³é¢„è­¦] {event_type}äº‹ä»¶ {event.id} ç™½åå•æœªå¯ç”¨ï¼Œçœä»½ '{province}' é€šè¿‡æ£€æŸ¥"
            )
            return True

        # æ£€æŸ¥çœä»½æ˜¯å¦åœ¨ç™½åå•ä¸­ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        for allowed_province in whitelist:
            if allowed_province in province or province in allowed_province:
                logger.debug(
                    f"[ç¾å®³é¢„è­¦] {event_type}äº‹ä»¶ {event.id} çœä»½ '{province}' åœ¨ç™½åå•ä¸­ï¼Œé€šè¿‡æ£€æŸ¥"
                )
                return True

        logger.info(
            f"[ç¾å®³é¢„è­¦] {event_type}äº‹ä»¶ {event.id} çœä»½ '{province}' ä¸åœ¨ç™½åå• {whitelist} ä¸­ï¼Œè¿‡æ»¤"
        )
        return False

    def _extract_province(self, event: DisasterEvent) -> str | None:
        """ä»äº‹ä»¶ä¸­æå–çœä»½ä¿¡æ¯"""
        if isinstance(event.data, EarthquakeData):
            earthquake = event.data
            
            # æ–¹æ³•1ï¼šç›´æ¥ä½¿ç”¨provinceå­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰
            if earthquake.province:
                return earthquake.province
            
            # æ–¹æ³•2ï¼šä»place_nameä¸­æå–çœä»½ï¼ˆé€‚ç”¨äºä¸­å›½åœ°éœ‡ï¼‰
            if earthquake.place_name:
                place_name = earthquake.place_name
                # å°è¯•ä»åœ°åä¸­æå–çœä»½
                # ä¾‹å¦‚ï¼š"å››å·å‡‰å±±å·ç›æºå¿" -> "å››å·"
                # "æ–°ç–†å·´éŸ³éƒ­æ¥å·è‹¥ç¾Œå¿" -> "æ–°ç–†"
                province_list = [
                    "åŒ—äº¬", "å¤©æ´¥", "æ²³åŒ—", "å±±è¥¿", "å†…è’™å¤",
                    "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ", "ä¸Šæµ·", "æ±Ÿè‹",
                    "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ",
                    "æ²³å—", "æ¹–åŒ—", "æ¹–å—", "å¹¿ä¸œ", "å¹¿è¥¿",
                    "æµ·å—", "é‡åº†", "å››å·", "è´µå·", "äº‘å—",
                    "è¥¿è—", "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å®å¤",
                    "æ–°ç–†", "å°æ¹¾", "é¦™æ¸¯", "æ¾³é—¨"
                ]
                
                for province in province_list:
                    if place_name.startswith(province):
                        return province
                    
        elif isinstance(event.data, WeatherAlarmData):
            # æ°”è±¡é¢„è­¦é€šå¸¸åœ¨æ ‡é¢˜ä¸­åŒ…å«çœä»½ä¿¡æ¯
            weather = event.data
            if weather.headline:
                province_list = [
                    "åŒ—äº¬", "å¤©æ´¥", "æ²³åŒ—", "å±±è¥¿", "å†…è’™å¤",
                    "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ", "ä¸Šæµ·", "æ±Ÿè‹",
                    "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ",
                    "æ²³å—", "æ¹–åŒ—", "æ¹–å—", "å¹¿ä¸œ", "å¹¿è¥¿",
                    "æµ·å—", "é‡åº†", "å››å·", "è´µå·", "äº‘å—",
                    "è¥¿è—", "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å®å¤",
                    "æ–°ç–†", "å°æ¹¾", "é¦™æ¸¯", "æ¾³é—¨"
                ]
                
                for province in province_list:
                    if province in weather.headline or province in weather.title:
                        return province
        
        return None

    def _check_thresholds(self, event: DisasterEvent) -> bool:
        """æ£€æŸ¥é˜ˆå€¼"""
        if not isinstance(event.data, EarthquakeData):
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} ä¸æ˜¯åœ°éœ‡äº‹ä»¶ï¼Œè·³è¿‡é˜ˆå€¼æ£€æŸ¥")
            return True  # éåœ°éœ‡äº‹ä»¶ä¸æ£€æŸ¥

        earthquake = event.data

        logger.debug(
            f"[ç¾å®³é¢„è­¦] æ£€æŸ¥åœ°éœ‡äº‹ä»¶é˜ˆå€¼ - éœ‡çº§: {earthquake.magnitude}, çƒˆåº¦: {earthquake.intensity}, éœ‡åº¦: {earthquake.scale}"
        )
        logger.debug(
            f"[ç¾å®³é¢„è­¦] é…ç½®é˜ˆå€¼ - æœ€å°éœ‡çº§: {self.thresholds.get('min_magnitude')}, æœ€å°çƒˆåº¦: {self.thresholds.get('min_intensity')}, æœ€å°éœ‡åº¦: {self.thresholds.get('min_scale')}"
        )

        # æ£€æŸ¥éœ‡çº§
        min_magnitude = self.thresholds.get("min_magnitude", 0)
        if earthquake.magnitude is not None and earthquake.magnitude < min_magnitude:
            logger.debug(
                f"[ç¾å®³é¢„è­¦] éœ‡çº§ {earthquake.magnitude} < æœ€å°éœ‡çº§ {min_magnitude}"
            )
            return False

        # æ£€æŸ¥çƒˆåº¦
        min_intensity = self.thresholds.get("min_intensity")
        if (
            min_intensity is not None
            and earthquake.intensity is not None
            and earthquake.intensity < min_intensity
        ):
            logger.debug(
                f"[ç¾å®³é¢„è­¦] çƒˆåº¦ {earthquake.intensity} < æœ€å°çƒˆåº¦ {min_intensity}"
            )
            return False

        # æ£€æŸ¥éœ‡åº¦
        min_scale = self.thresholds.get("min_scale")
        if min_scale is not None and earthquake.scale is not None:
            try:
                # ç¡®ä¿scaleæ˜¯æ•°å€¼ç±»å‹
                scale_value = float(earthquake.scale)
                if scale_value < min_scale:
                    logger.debug(
                        f"[ç¾å®³é¢„è­¦] éœ‡åº¦ {scale_value} < æœ€å°éœ‡åº¦ {min_scale}"
                    )
                    return False
            except (ValueError, TypeError):
                logger.debug(f"[ç¾å®³é¢„è­¦] éœ‡åº¦å€¼æ— æ³•è½¬æ¢ä¸ºæ•°å€¼: {earthquake.scale}")
                # å¦‚æœæ— æ³•è½¬æ¢ï¼Œè·³è¿‡éœ‡åº¦æ£€æŸ¥
                pass

        logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} é€šè¿‡æ‰€æœ‰é˜ˆå€¼æ£€æŸ¥")
        return True

    async def push_event(self, event: DisasterEvent) -> bool:
        """æ¨é€äº‹ä»¶"""
        logger.debug(f"[ç¾å®³é¢„è­¦] å¤„ç†äº‹ä»¶æ¨é€: {event.id}")

        # å…ˆå»é‡æ£€æŸ¥ - åªæ¨é€é¦–æ¬¡æ¥æ”¶çš„äº‹ä»¶
        if not self.deduplicator.should_push_event(event):
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} è¢«å»é‡å™¨è¿‡æ»¤")
            return False

        if not self.should_push_event(event):
            # è¯¦ç»†è¿‡æ»¤åŸå› å·²ç»åœ¨should_push_eventä¸­è®°å½•ï¼Œè¿™é‡Œåªè®°å½•ç®€å•ä¿¡æ¯
            logger.debug(f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} æœªé€šè¿‡æ¨é€æ¡ä»¶æ£€æŸ¥")
            return False

        # è®°å½•äº‹ä»¶ï¼ˆç”¨äºåç»­å»é‡ï¼‰
        self.deduplicator.record_event(event)

        try:
            # æ„å»ºæ¶ˆæ¯
            message = self._build_message(event)
            logger.debug(f"[ç¾å®³é¢„è­¦] æ¶ˆæ¯æ„å»ºå®Œæˆ: {message}")

            # è·å–ç›®æ ‡ä¼šè¯
            target_sessions = self.target_sessions or self._get_all_sessions()
            logger.debug(f"[ç¾å®³é¢„è­¦] ç›®æ ‡ä¼šè¯: {target_sessions}")

            if not target_sessions:
                logger.warning("[ç¾å®³é¢„è­¦] æ²¡æœ‰é…ç½®ç›®æ ‡ä¼šè¯ï¼Œæ— æ³•æ¨é€æ¶ˆæ¯")
                return False

            # æ¨é€æ¶ˆæ¯
            push_success_count = 0
            for session in target_sessions:
                try:
                    await self._send_message(session, message)
                    logger.info(f"[ç¾å®³é¢„è­¦] æ¶ˆæ¯å·²æ¨é€åˆ° {session}")
                    push_success_count += 1
                except Exception as e:
                    logger.error(f"[ç¾å®³é¢„è­¦] æ¨é€åˆ° {session} å¤±è´¥: {e}")

            # è®°å½•æ¨é€
            self._record_push(event)
            logger.info(
                f"[ç¾å®³é¢„è­¦] äº‹ä»¶ {event.id} æ¨é€å®Œæˆï¼ŒæˆåŠŸæ¨é€åˆ° {push_success_count} ä¸ªä¼šè¯"
            )
            return push_success_count > 0

        except Exception as e:
            logger.error(f"[ç¾å®³é¢„è­¦] æ¨é€äº‹ä»¶å¤±è´¥: {e}")
            return False

    def _build_message(self, event: DisasterEvent) -> MessageChain:
        """æ„å»ºæ¶ˆæ¯ - ç»Ÿä¸€ä½¿ç”¨ä¸“é—¨æ ¼å¼åŒ–å™¨ï¼Œç§»é™¤é€šç”¨æ¨¡æ¿ç³»ç»Ÿ"""
        # æ‰€æœ‰äº‹ä»¶ç±»å‹éƒ½ä½¿ç”¨ä¸“é—¨çš„æ ¼å¼åŒ–å™¨ï¼Œç¡®ä¿åŠŸèƒ½å®Œæ•´æ€§å’Œä¸€è‡´æ€§
        if isinstance(event.data, WeatherAlarmData):
            # æ°”è±¡é¢„è­¦ä½¿ç”¨ä¸“é—¨çš„æ ¼å¼åŒ–å™¨
            message_text = MessageFormatter.format_weather_message(event.data)
        elif isinstance(event.data, TsunamiData):
            # æµ·å•¸é¢„è­¦ä½¿ç”¨ä¸“é—¨çš„æ ¼å¼åŒ–å™¨
            message_text = MessageFormatter.format_tsunami_message(event.data)
        elif isinstance(event.data, EarthquakeData):
            # åœ°éœ‡äº‹ä»¶ä½¿ç”¨ä¸“é—¨çš„æ ¼å¼åŒ–å™¨ - åŒ…å«å®Œæ•´çš„æ•°æ®æºè¯†åˆ«å’Œæ™ºèƒ½ä¿¡æ¯ç±»å‹
            message_text = MessageFormatter.format_earthquake_message(event.data)
        else:
            # æœªçŸ¥äº‹ä»¶ç±»å‹ï¼Œä½¿ç”¨åŸºç¡€æ ¼å¼åŒ–
            logger.warning(
                f"[ç¾å®³é¢„è­¦] æœªçŸ¥äº‹ä»¶ç±»å‹: {type(event.data)}ï¼Œä½¿ç”¨åŸºç¡€æ ¼å¼åŒ–"
            )
            message_text = f"ğŸš¨ã€æœªçŸ¥äº‹ä»¶ã€‘\nğŸ“‹äº‹ä»¶IDï¼š{event.id}\nâ°æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

        # æ„å»ºæ¶ˆæ¯é“¾
        chain = [Comp.Plain(message_text)]

        # æ·»åŠ åœ°å›¾é“¾æ¥ï¼ˆä»…åœ°éœ‡äº‹ä»¶ä¸”åŒ…å«ç»çº¬åº¦ï¼‰
        if self.include_map and isinstance(event.data, EarthquakeData):
            if event.data.latitude is not None and event.data.longitude is not None:
                map_url = self._generate_map_url(event.data)
                if map_url:
                    # å…³é”®ä¿®å¤ï¼šç»•è¿‡AstrBotçš„strip()é—®é¢˜
                    # 1. ä½¿ç”¨ç‹¬ç«‹çš„Plainç»„ä»¶ï¼Œç¡®ä¿æ¢è¡Œç¬¦ä¸è¢«strip()
                    # 2. åœ¨URLå‰æ·»åŠ ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…è¢«strip()å½±å“
                    # 3. ä½¿ç”¨æ¶ˆæ¯å¹³å°èƒ½è¯†åˆ«çš„æ¢è¡Œæ–¹å¼

                    # å…³é”®ä¿®å¤ï¼šä½¿ç”¨AstrBotå®˜æ–¹æ¨èçš„é›¶å®½ç©ºæ ¼è§£å†³æ–¹æ¡ˆ
                    # åœ¨æ¶ˆæ¯å‰åæ·»åŠ é›¶å®½ç©ºæ ¼ \u200b ä»¥ç»•è¿‡ strip() é—®é¢˜
                    # å‚è€ƒï¼šhttps://docs.astrbot.app/dev/star/guides/send-message#æ¶ˆæ¯çš„å‘é€

                    # å…³é”®ä¿®å¤ï¼šé›¶å®½ç©ºæ ¼ç ´åURLå®Œæ•´æ€§é—®é¢˜è§£å†³
                    # 1. æ¢è¡Œç»„ä»¶ä½¿ç”¨é›¶å®½ç©ºæ ¼ï¼ˆä¿æŠ¤æ¢è¡Œï¼‰
                    # 2. URLç»„ä»¶ç§»é™¤é›¶å®½ç©ºæ ¼ï¼ˆé¿å…å¹²æ‰°URLè¯†åˆ«ï¼‰
                    # 3. å¯¹URLè¿›è¡ŒURLç¼–ç ï¼Œç¡®ä¿ç‰¹æ®Šå­—ç¬¦æ­£ç¡®å¤„ç†

                    zero_width_space = "\u200b"

                    # æ¢è¡Œç»„ä»¶ï¼šä½¿ç”¨é›¶å®½ç©ºæ ¼ä¿æŠ¤æ¢è¡Œ
                    chain.append(
                        Comp.Plain(f"{zero_width_space}\nğŸ—ºï¸åœ°å›¾:{zero_width_space}")
                    )  # å—ä¿æŠ¤çš„æ¢è¡Œç»„ä»¶

                    # URLç»„ä»¶ï¼šç§»é™¤é›¶å®½ç©ºæ ¼ï¼Œé¿å…å¹²æ‰°URLè¯†åˆ«
                    # å¯¹URLè¿›è¡ŒURLç¼–ç ï¼Œç¡®ä¿ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦æ­£ç¡®å¤„ç†
                    encoded_map_url = urllib.parse.quote(map_url, safe=":/?&=+")
                    chain.append(Comp.Plain(f" {encoded_map_url}"))  # å¹²å‡€çš„URLç»„ä»¶

        return MessageChain(chain)

    def _get_source_display_name(self, source) -> str:
        """è·å–æ•°æ®æºçš„æ˜¾ç¤ºåç§°"""
        source_names = {
            "fan_studio_usgs": "USGS åœ°éœ‡æƒ…æŠ¥",
            "fan_studio_cenc": "ä¸­å›½åœ°éœ‡å°ç½‘",
            "fan_studio_cea": "ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘",
            "fan_studio_cwa": "å°æ¹¾ä¸­å¤®æ°”è±¡ç½²",
            "fan_studio_weather": "æ°”è±¡é¢„è­¦",
            "fan_studio_tsunami": "æµ·å•¸é¢„è­¦",
            "wolfx_jma_eew": "æ—¥æœ¬æ°”è±¡å…",
            "wolfx_cenc_eew": "ä¸­å›½åœ°éœ‡å°ç½‘é¢„è­¦",
            "wolfx_cwa_eew": "å°æ¹¾åœ°éœ‡é¢„è­¦",
            "p2p_earthquake": "P2Påœ°éœ‡æƒ…æŠ¥",
            "p2p_eew": "P2Pç´§æ€¥åœ°éœ‡é€ŸæŠ¥",
            "global_quake": "Global Quake",
        }
        return (
            source_names.get(source.value, "ç¾å®³é¢„è­¦")
            if hasattr(source, "value")
            else "ç¾å®³é¢„è­¦"
        )

    def _generate_map_url(self, earthquake: EarthquakeData) -> str | None:
        """ç”Ÿæˆåœ°å›¾é“¾æ¥ - ä¼˜åŒ–URLé•¿åº¦å’Œå¯è¯†åˆ«æ€§"""
        if earthquake.latitude is None or earthquake.longitude is None:
            return None

        lat = earthquake.latitude
        lon = earthquake.longitude
        zoom = self.map_zoom_level

        # æ„å»ºéœ‡ä¸­ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå‡å°‘URLé•¿åº¦ï¼‰
        magnitude_info = f"M{earthquake.magnitude}" if earthquake.magnitude else "åœ°éœ‡"
        location_info = earthquake.place_name if earthquake.place_name else "éœ‡ä¸­ä½ç½®"

        if self.map_provider == "openstreetmap":
            # OpenStreetMap ç®€æ´æ ¼å¼
            return f"https://www.openstreetmap.org/?mlat={lat}&mlon={lon}&zoom={zoom}"

        elif self.map_provider == "google":
            # Google Maps ç®€æ´æ ¼å¼
            return f"https://maps.google.com/maps?q={lat},{lon}&z={zoom}"

        elif self.map_provider == "baidu":
            # ç™¾åº¦åœ°å›¾ç›´æ¥ä½¿ç”¨WGS84åæ ‡ï¼ˆå®é™…è§‚æµ‹è¯æ˜ç²¾åº¦è¶³å¤Ÿï¼‰
            baidu_map_url = f"https://api.map.baidu.com/marker?location={lat},{lon}&zoom={zoom}&title={magnitude_info}+Epicenter&content={location_info[:32]}&output=html"
            logger.info("[ç¾å®³é¢„è­¦] å·²ç”Ÿæˆç™¾åº¦åœ°å›¾é“¾æ¥ï¼ˆä½¿ç”¨WGS84åæ ‡ï¼‰")
            return baidu_map_url

        elif self.map_provider == "amap":
            # é«˜å¾·åœ°å›¾ç®€æ´æ ¼å¼
            return f"https://uri.amap.com/marker?position={lon},{lat}&zoom={zoom}"


    def _get_all_sessions(self) -> list[str]:
        """è·å–æ‰€æœ‰ä¼šè¯"""
        # è¿™é‡Œéœ€è¦å®ç°è·å–æ‰€æœ‰æ´»è·ƒä¼šè¯çš„é€»è¾‘
        # æš‚æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œè®©æ’ä»¶ä¸»ç±»æ¥å¤„ç†
        return []

    async def _send_message(self, session: str, message: MessageChain):
        """å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šä¼šè¯"""
        await self.context.send_message(session, message)

    def _record_push(self, event: DisasterEvent):
        """è®°å½•æ¨é€"""
        event_id = self._get_event_id(event)

        # è®°å½•æ¨é€ä¿¡æ¯
        push_info = {
            "timestamp": datetime.now(),
            "event_id": event_id,
            "disaster_type": event.disaster_type.value,
            "is_final": self._is_final_report(event),
        }

        self.event_push_records[event_id].append(push_info)

        # å¦‚æœæ˜¯æœ€ç»ˆæŠ¥ï¼Œæ ‡è®°ä¸ºå·²æ¨é€æœ€ç»ˆæŠ¥
        if self._is_final_report(event):
            self.final_reports.add(event_id)

    def get_push_stats(self) -> dict[str, Any]:
        """è·å–æ¨é€ç»Ÿè®¡"""
        total_events = len(self.event_push_records)
        total_pushes = sum(len(records) for records in self.event_push_records.values())
        final_reports_pushed = len(self.final_reports)

        return {
            "total_events": total_events,
            "total_pushes": total_pushes,
            "final_reports_pushed": final_reports_pushed,
            "recent_events": self._get_recent_events(),
        }

    def _get_recent_events(self, hours: int = 24) -> list[dict]:
        """è·å–æœ€è¿‘çš„äº‹ä»¶"""
        recent_time = datetime.now() - timedelta(hours=hours)
        recent_events = []

        for event_id, records in self.event_push_records.items():
            recent_records = [
                record for record in records if record["timestamp"] > recent_time
            ]

            if recent_records:
                recent_events.append(
                    {
                        "event_id": event_id,
                        "push_count": len(recent_records),
                        "last_push": max(
                            record["timestamp"] for record in recent_records
                        ),
                    }
                )

        return sorted(recent_events, key=lambda x: x["last_push"], reverse=True)

    def cleanup_old_records(self, days: int = 7):
        """æ¸…ç†æ—§è®°å½•"""
        cutoff_time = datetime.now() - timedelta(days=days)

        # æ¸…ç†äº‹ä»¶æ¨é€è®°å½•
        for event_id in list(self.event_push_records.keys()):
            records = self.event_push_records[event_id]
            recent_records = [
                record for record in records if record["timestamp"] > cutoff_time
            ]

            if recent_records:
                self.event_push_records[event_id] = recent_records
            else:
                del self.event_push_records[event_id]

        # æ¸…ç†æœ€ç»ˆæŠ¥è®°å½•
        self.final_reports.clear()

        logger.info(f"[ç¾å®³é¢„è­¦] å·²æ¸…ç† {days} å¤©å‰çš„æ¨é€è®°å½•")


class MessageFormatter:
    """æ¶ˆæ¯æ ¼å¼åŒ–å™¨"""

    @staticmethod
    def format_earthquake_message(earthquake: EarthquakeData) -> str:
        """æ ¼å¼åŒ–åœ°éœ‡æ¶ˆæ¯ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«å®Œæ•´ä¿¡æ¯å’Œæ•°æ®æº"""
        # åŸºäºæ•°æ®æºæ„å»ºæ™ºèƒ½æ ‡é¢˜ - ä¿®å¤æ•°æ®æºä¿¡æ¯æ˜¾ç¤º
        source_name = MessageFormatter._get_source_display_name(earthquake.source)
        lines = [f"ğŸš¨ã€{source_name}ã€‘"]

        # éœ‡ä¸­ - ä¿®å¤å­—æ®µå‘½åï¼Œä½¿ç”¨"éœ‡ä¸­"è€Œé"åœ°ç‚¹"
        if earthquake.place_name:
            lines.append(f"ğŸ“éœ‡ä¸­ï¼š{earthquake.place_name}")

        # æ—¶é—´ - æ·»åŠ æ—¶åŒºä¿¡æ¯ï¼ŒåŸºäºæ•°æ®æºæ™ºèƒ½è¯†åˆ«
        if earthquake.shock_time:
            timezone = MessageFormatter._get_source_timezone(earthquake.source)
            lines.append(
                f"â°æ—¶é—´ï¼š{earthquake.shock_time.strftime('%Y-%m-%d %H:%M:%S')} ({timezone})"
            )

        # éœ‡çº§
        if earthquake.magnitude is not None:
            lines.append(f"ğŸ“Šéœ‡çº§ï¼šM {earthquake.magnitude}")

        # æ·±åº¦
        if earthquake.depth is not None:
            lines.append(f"ğŸ”ï¸æ·±åº¦ï¼š{earthquake.depth} km")

        # çƒˆåº¦/éœ‡åº¦ - æ™ºèƒ½æ˜¾ç¤ºï¼Œç¡®ä¿ä¸ç¼ºå¤±
        if earthquake.intensity is not None:
            lines.append(f"ğŸ’¥çƒˆåº¦ï¼š{earthquake.intensity}")
        elif earthquake.scale is not None:
            lines.append(f"ğŸ’¥éœ‡åº¦ï¼š{earthquake.scale}")
        else:
            # éƒ½æ²¡æœ‰æ—¶æ˜¾ç¤º"æ— "
            lines.append("ğŸ’¥çƒˆåº¦ï¼šæ— ")

        # æ›´æ–°ä¿¡æ¯ - ç¡®ä¿æ˜¾ç¤ºæŠ¥æ•°
        if earthquake.updates > 0:
            lines.append(f"ğŸ”„æŠ¥æ•°ï¼šç¬¬ {earthquake.updates} æŠ¥")
        else:
            lines.append("ğŸ”„æŠ¥æ•°ï¼šç¬¬ 1 æŠ¥")

        # æœ€ç»ˆæŠ¥æ ‡è¯† - æ™ºèƒ½æ˜¾ç¤ºï¼Œåªå¯¹æœ‰æœ€ç»ˆæŠ¥æœºåˆ¶çš„æ•°æ®æºæ˜¾ç¤º
        if MessageFormatter._has_final_report_support(earthquake.source):
            if earthquake.is_final:
                lines.append("ğŸ”šæœ€ç»ˆæŠ¥ï¼šæ˜¯")
            else:
                lines.append("ğŸ”šæœ€ç»ˆæŠ¥ï¼šå¦")

        # ä¿¡æ¯ç±»å‹ - åŸºäºAPIæ–‡æ¡£å®ç°ä¸“ä¸šæµ‹å®šç±»å‹è¯†åˆ«
        if earthquake.info_type:
            # åŸºäºæ•°æ®æºå’Œinfo_typeå­—æ®µï¼Œæä¾›ä¸“ä¸šçš„æµ‹å®šç±»å‹æ˜¾ç¤º
            if earthquake.source == DataSource.FAN_STUDIO_CENC:
                # CENC: åŸºäºinfoTypeNameå­—æ®µ
                if "[æ­£å¼æµ‹å®š]" in earthquake.info_type:
                    info_type = "ä¸­å›½åœ°éœ‡å°ç½‘ [æ­£å¼æµ‹å®š]"
                elif "[è‡ªåŠ¨æµ‹å®š]" in earthquake.info_type:
                    info_type = "ä¸­å›½åœ°éœ‡å°ç½‘ [è‡ªåŠ¨æµ‹å®š]"
                else:
                    info_type = f"ä¸­å›½åœ°éœ‡å°ç½‘ {earthquake.info_type}"

            elif earthquake.source == DataSource.FAN_STUDIO_USGS:
                # USGS: åŸºäºinfoTypeNameå­—æ®µ
                if earthquake.info_type.lower() == "automatic":
                    info_type = "USGSåœ°éœ‡æƒ…æŠ¥ [è‡ªåŠ¨æµ‹å®š]"
                elif earthquake.info_type.lower() == "reviewed":
                    info_type = "USGSåœ°éœ‡æƒ…æŠ¥ [äººå·¥å¤æ ¸]"
                else:
                    info_type = f"USGSåœ°éœ‡æƒ…æŠ¥ {earthquake.info_type}"

            elif earthquake.source == DataSource.FAN_STUDIO_CEA:
                # CEA: ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘ï¼ŒåŸºäºå®é™…æ•°æ®ç‰¹å¾
                info_type = "ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘"

            elif earthquake.source == DataSource.FAN_STUDIO_CWA:
                # CWA: å°æ¹¾ä¸­å¤®æ°”è±¡ç½²ï¼ŒåŸºäºå®é™…æ•°æ®ç‰¹å¾
                info_type = "å°æ¹¾ä¸­å¤®æ°”è±¡ç½²"

            elif earthquake.source in [
                DataSource.WOLFX_CENC_EEW,
                DataSource.WOLFX_JMA_EEW,
                DataSource.WOLFX_CWA_EEW,
            ]:
                # Wolfx EEW: åŸºäºtypeå­—æ®µ
                raw_type = earthquake.raw_data.get("type", "")
                if raw_type == "automatic":
                    if earthquake.source == DataSource.WOLFX_CENC_EEW:
                        info_type = "ä¸­å›½åœ°éœ‡å°ç½‘é¢„è­¦ [è‡ªåŠ¨æµ‹å®š]"
                    elif earthquake.source == DataSource.WOLFX_JMA_EEW:
                        info_type = "æ—¥æœ¬æ°”è±¡å…é¢„è­¦ [è‡ªåŠ¨æµ‹å®š]"
                    else:
                        info_type = "å°æ¹¾åœ°éœ‡é¢„è­¦ [è‡ªåŠ¨æµ‹å®š]"
                elif raw_type == "reviewed":
                    if earthquake.source == DataSource.WOLFX_CENC_EEW:
                        info_type = "ä¸­å›½åœ°éœ‡å°ç½‘é¢„è­¦ [æ­£å¼æµ‹å®š]"
                    elif earthquake.source == DataSource.WOLFX_JMA_EEW:
                        info_type = "æ—¥æœ¬æ°”è±¡å…é¢„è­¦ [æ­£å¼æµ‹å®š]"
                    else:
                        info_type = "å°æ¹¾åœ°éœ‡é¢„è­¦ [æ­£å¼æµ‹å®š]"
                else:
                    # åŸºäºæ•°æ®æºçš„ä¸“ä¸šæ˜¾ç¤º
                    if earthquake.source == DataSource.WOLFX_CENC_EEW:
                        info_type = "ä¸­å›½åœ°éœ‡å°ç½‘é¢„è­¦"
                    elif earthquake.source == DataSource.WOLFX_JMA_EEW:
                        info_type = "æ—¥æœ¬æ°”è±¡å…é¢„è­¦"
                    else:
                        info_type = "å°æ¹¾åœ°éœ‡é¢„è­¦"

            elif earthquake.source == DataSource.P2P_EARTHQUAKE:
                # P2Påœ°éœ‡æƒ…å ±: åŸºäºissue.typeå­—æ®µ
                issue_type = earthquake.raw_data.get("issue", {}).get("type", "")
                if issue_type == "DetailScale":
                    info_type = "æ—¥æœ¬æ°”è±¡å… [è©³ç´°éœ‡åº¦]"
                elif issue_type == "ScalePrompt":
                    info_type = "æ—¥æœ¬æ°”è±¡å… [éœ‡åº¦é€ŸæŠ¥]"
                elif issue_type == "Destination":
                    info_type = "æ—¥æœ¬æ°”è±¡å… [éœ‡æºæƒ…å ±]"
                else:
                    info_type = f"æ—¥æœ¬æ°”è±¡å… [{issue_type}]"

            elif earthquake.source == DataSource.P2P_EEW:
                # P2Pç·Šæ€¥åœ°éœ‡é€Ÿå ±: å›ºå®šç±»å‹
                info_type = "æ—¥æœ¬æ°”è±¡å… [ç·Šæ€¥åœ°éœ‡é€Ÿå ±]"

            else:
                info_type = f"åœ°éœ‡æƒ…å ± {earthquake.info_type}"
        else:
            # åŸºäºAPIæ–‡æ¡£å’Œç°æœ‰ä»£ç å®ç°ï¼Œæä¾›å‡†ç¡®çš„é»˜è®¤ç±»å‹
            if earthquake.source == DataSource.FAN_STUDIO_CENC:
                # CENC: æ ¹æ®is_finalåˆ¤æ–­æ­£å¼/è‡ªåŠ¨æµ‹å®š (APIæ–‡æ¡£ç¬¬220è¡Œ)
                info_type = (
                    "ä¸­å›½åœ°éœ‡å°ç½‘ [æ­£å¼æµ‹å®š]"
                    if earthquake.is_final
                    else "ä¸­å›½åœ°éœ‡å°ç½‘ [è‡ªåŠ¨æµ‹å®š]"
                )

            elif earthquake.source == DataSource.FAN_STUDIO_USGS:
                # USGS: åŸºäºis_finalçš„æ™ºèƒ½åˆ¤æ–­
                info_type = (
                    "USGSåœ°éœ‡æƒ…æŠ¥ [äººå·¥å¤æ ¸]"
                    if earthquake.is_final
                    else "USGSåœ°éœ‡æƒ…æŠ¥ [è‡ªåŠ¨æµ‹å®š]"
                )

            elif earthquake.source == DataSource.FAN_STUDIO_CEA:
                # CEA: ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘ï¼ŒAPIæ–‡æ¡£ä¸­æ— ç‰¹å®šç±»å‹æ ‡è¯†
                info_type = "ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘"

            elif earthquake.source == DataSource.FAN_STUDIO_CWA:
                # CWA: å°æ¹¾ä¸­å¤®æ°”è±¡ç½²ï¼ŒAPIæ–‡æ¡£ä¸­æ— ç‰¹å®šç±»å‹æ ‡è¯†
                info_type = "å°æ¹¾ä¸­å¤®æ°”è±¡ç½²"

            elif earthquake.source == DataSource.P2P_EARTHQUAKE:
                # P2Påœ°éœ‡æƒ…å ±: åŸºäºAPIæ–‡æ¡£ï¼Œé»˜è®¤æ˜¾ç¤º
                info_type = "æ—¥æœ¬æ°”è±¡å… [åœ°éœ‡æƒ…å ±]"

            elif earthquake.source == DataSource.P2P_EEW:
                # P2Pç·Šæ€¥åœ°éœ‡é€Ÿå ±: åŸºäºAPIæ–‡æ¡£
                info_type = "æ—¥æœ¬æ°”è±¡å… [ç·Šæ€¥åœ°éœ‡é€Ÿå ±]"

            elif earthquake.source in [
                DataSource.WOLFX_JMA_EEW,
                DataSource.WOLFX_CENC_EEW,
                DataSource.WOLFX_CWA_EEW,
            ]:
                # Wolfx EEW: ç´§æ€¥åœ°éœ‡é€ŸæŠ¥
                info_type = "ç·Šæ€¥åœ°éœ‡é€Ÿå ±"

            else:
                info_type = "åœ°éœ‡æƒ…å ±"

        lines.append(f"ğŸ“‹ä¿¡æ¯ç±»å‹ï¼š{info_type}")

        return "\n".join(lines)

    @staticmethod
    def _get_source_timezone(source) -> str:
        """è·å–æ•°æ®æºçš„æ—¶åŒºä¿¡æ¯ - åŸºäºAPIæ–‡æ¡£åˆ†æ"""
        # åŸºäºä¸‰ä»½APIæ–‡æ¡£çš„æ—¶åŒºåˆ†æ
        timezone_mapping = {
            # P2Påœ°éœ‡æƒ…å ± - UTC+9 (æ—¥æœ¬æ ‡å‡†æ—¶é—´)
            "p2p_earthquake": "UTC+9",
            "p2p_eew": "UTC+9",
            # æ—¥æœ¬æ°”è±¡å… - UTC+9
            "wolfx_jma_eew": "UTC+9",
            # ä¸­å›½æ•°æ®æº - UTC+8 (åŒ—äº¬æ—¶é—´)
            "fan_studio_cenc": "UTC+8",
            "fan_studio_cea": "UTC+8",
            "fan_studio_cwa": "UTC+8",
            "fan_studio_weather": "UTC+8",
            "fan_studio_tsunami": "UTC+8",
            "wolfx_cenc_eew": "UTC+8",
            "wolfx_cwa_eew": "UTC+8",
            # USGS - UTC+8 (æ–‡æ¡£æ˜ç¡®è¯´æ˜)
            "fan_studio_usgs": "UTC+8",
            # å…¶ä»–å›½é™…æ•°æ®æº - é»˜è®¤ä¸ºUTC+8
            "global_quake": "UTC+8",
        }

        if hasattr(source, "value"):
            return timezone_mapping.get(source.value, "UTC+8")
        return "UTC+8"

    @staticmethod
    def _get_source_display_name(source) -> str:
        """è·å–æ•°æ®æºçš„æ˜¾ç¤ºåç§° - å¤ç”¨ä¸»ç±»ä¸­çš„é€»è¾‘"""
        source_names = {
            "fan_studio_usgs": "USGS åœ°éœ‡æƒ…æŠ¥",
            "fan_studio_cenc": "ä¸­å›½åœ°éœ‡å°ç½‘",
            "fan_studio_cea": "ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘",
            "fan_studio_cwa": "å°æ¹¾ä¸­å¤®æ°”è±¡ç½²",
            "fan_studio_weather": "æ°”è±¡é¢„è­¦",
            "fan_studio_tsunami": "æµ·å•¸é¢„è­¦",
            "wolfx_jma_eew": "æ—¥æœ¬æ°”è±¡å…",
            "wolfx_cenc_eew": "ä¸­å›½åœ°éœ‡å°ç½‘é¢„è­¦",
            "wolfx_cwa_eew": "å°æ¹¾åœ°éœ‡é¢„è­¦",
            "p2p_earthquake": "P2Påœ°éœ‡æƒ…æŠ¥",
            "p2p_eew": "P2Pç´§æ€¥åœ°éœ‡é€ŸæŠ¥",
            "global_quake": "Global Quake",
        }
        return (
            source_names.get(source.value, "åœ°éœ‡æƒ…æŠ¥")
            if hasattr(source, "value")
            else "åœ°éœ‡æƒ…æŠ¥"
        )

    @staticmethod
    def _has_final_report_support(source) -> bool:
        """åˆ¤æ–­æ•°æ®æºæ˜¯å¦æ”¯æŒæœ€ç»ˆæŠ¥çŠ¶æ€"""
        # åŸºäºAPIæ–‡æ¡£åˆ†æï¼Œåªæœ‰ä»¥ä¸‹æ•°æ®æºæ”¯æŒæœ€ç»ˆæŠ¥æœºåˆ¶
        final_report_supported_sources = {
            DataSource.FAN_STUDIO_CEA,  # ä¸­å›½åœ°éœ‡é¢„è­¦ç½‘ - æœ‰updateså­—æ®µ
            DataSource.FAN_STUDIO_CWA,  # å°æ¹¾ä¸­å¤®æ°”è±¡ç½² - æœ‰updateså­—æ®µ
            DataSource.P2P_EARTHQUAKE,  # P2Påœ°éœ‡æƒ…å ± - æœ‰å®Œæ•´çš„æŠ¥æ•°æ›´æ–°æœºåˆ¶
            DataSource.P2P_EEW,  # P2Pç´§æ€¥åœ°éœ‡é€ŸæŠ¥ - æœ‰æŠ¥æ•°æœºåˆ¶
            DataSource.WOLFX_JMA_EEW,  # Wolfx JMA - æœ‰isFinalå­—æ®µ
            DataSource.WOLFX_CENC_EEW,  # Wolfx CENC - æœ‰ReportNumå­—æ®µ
            DataSource.WOLFX_CWA_EEW,  # Wolfx CWA - æœ‰ReportNumå­—æ®µ
        }

        # ä¸æ”¯æŒæœ€ç»ˆæŠ¥çš„æ•°æ®æºï¼ˆå•æ¬¡æµ‹å®šï¼Œæ— æ›´æ–°æœºåˆ¶ï¼‰
        # FAN_STUDIO_CENC - æ­£å¼æµ‹å®šï¼Œæ— æ›´æ–°
        # FAN_STUDIO_USGS - å•æ¬¡æµ‹å®š
        # FAN_STUDIO_EMSC - å•æ¬¡æµ‹å®š
        # å…¶ä»–éåœ°éœ‡æ•°æ®æº

        return source in final_report_supported_sources

    @staticmethod
    def format_tsunami_message(tsunami: TsunamiData) -> str:
        """æ ¼å¼åŒ–æµ·å•¸æ¶ˆæ¯ - ä¸°å¯Œç‰ˆæœ¬ï¼ŒåŒ…å«æ›´å¤šå®ç”¨ä¿¡æ¯"""
        lines = ["ğŸŒŠã€æµ·å•¸é¢„è­¦ã€‘"]

        # æ ‡é¢˜å’Œçº§åˆ«
        if tsunami.title:
            lines.append(f"ğŸ“‹{tsunami.title}")
        if tsunami.level:
            lines.append(f"âš ï¸çº§åˆ«ï¼š{tsunami.level}")

        # å‘å¸ƒå•ä½
        if tsunami.org_unit:
            lines.append(f"ğŸ¢å‘å¸ƒï¼š{tsunami.org_unit}")

        # å‘å¸ƒæ—¶é—´ - æ·»åŠ æ—¶åŒºä¿¡æ¯
        if tsunami.issue_time:
            timezone = MessageFormatter._get_source_timezone(tsunami.source)
            lines.append(
                f"â°å‘å¸ƒæ—¶é—´ï¼š{tsunami.issue_time.strftime('%Y-%m-%d %H:%M:%S')} ({timezone})"
            )

        # å¼•å‘åœ°éœ‡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if tsunami.subtitle:
            lines.append(f"ğŸŒéœ‡æºï¼š{tsunami.subtitle}")

        # é¢„æŠ¥åŒºåŸŸè¯¦ç»†ä¿¡æ¯
        if tsunami.forecasts:
            # æ˜¾ç¤ºå‰2ä¸ªåŒºåŸŸçš„è¯¦ç»†ä¿¡æ¯
            for i, forecast in enumerate(tsunami.forecasts[:2]):
                area_name = forecast.get("name", "")
                arrival_time = forecast.get("estimatedArrivalTime", "")
                max_wave = forecast.get("maxWaveHeight", "")
                area_level = forecast.get("warningLevel", "")

                if area_name:
                    # åŸºç¡€åŒºåŸŸä¿¡æ¯
                    area_info = f"ğŸ“{area_name}"

                    # æ·»åŠ è­¦æŠ¥çº§åˆ«ï¼ˆå¦‚æœä¸ä¸»çº§åˆ«ä¸åŒï¼‰
                    if area_level and area_level != tsunami.level:
                        area_info += f" [{area_level}]"

                    # æ·»åŠ é¢„è®¡åˆ°è¾¾æ—¶é—´
                    if arrival_time:
                        area_info += f" é¢„è®¡{arrival_time}åˆ°è¾¾"

                    # æ·»åŠ é¢„ä¼°æ³¢é«˜
                    if max_wave:
                        area_info += f" æ³¢é«˜{max_wave}cm"

                    lines.append(area_info)

            # å¦‚æœè¿˜æœ‰æ›´å¤šåŒºåŸŸï¼Œæ˜¾ç¤ºæ€»æ•°
            if len(tsunami.forecasts) > 2:
                lines.append(f"  ...ç­‰{len(tsunami.forecasts)}ä¸ªé¢„æŠ¥åŒºåŸŸ")

        # ç›‘æµ‹ç«™å®æ—¶æ•°æ®ï¼ˆæ˜¾ç¤ºå‰2ä¸ªç›‘æµ‹ç«™ï¼‰
        if tsunami.monitoring_stations:
            lines.append("ğŸ“Šç›‘æµ‹æ•°æ®ï¼š")
            for i, station in enumerate(tsunami.monitoring_stations[:2]):
                station_name = station.get("stationName", "")
                location = station.get("location", "")
                max_wave = station.get("maxWaveHeight", "")
                monitor_time = station.get("time", "")

                if station_name:
                    station_info = f"  â€¢{station_name}"
                    if location:
                        station_info += f"({location})"
                    if max_wave:
                        station_info += f" æ³¢é«˜{max_wave}cm"
                    if monitor_time:
                        station_info += f" {monitor_time}"
                    lines.append(station_info)

            # å¦‚æœè¿˜æœ‰æ›´å¤šç›‘æµ‹ç«™ï¼Œæ˜¾ç¤ºæ€»æ•°
            if len(tsunami.monitoring_stations) > 2:
                lines.append(f"  ...ç­‰{len(tsunami.monitoring_stations)}ä¸ªç›‘æµ‹ç«™")

        # äº‹ä»¶ç¼–ç ï¼ˆç”¨äºè¿½è¸ªåŒä¸€äº‹ä»¶çš„æ›´æ–°ï¼‰
        if tsunami.code:
            lines.append(f"ğŸ”„äº‹ä»¶ç¼–å·ï¼š{tsunami.code}")

        # è¯¦ç»†ä¿¡æ¯é“¾æ¥ï¼ˆä»åŸå§‹æ•°æ®ä¸­æå–ï¼‰
        details = tsunami.raw_data.get("details", {})
        if details:
            html_url = details.get("htmlUrl", "")
            if html_url:
                lines.append(f"ğŸ“„è¯¦æƒ…ï¼š{html_url}")

        return "\n".join(lines)

    @staticmethod
    def format_weather_message(weather: WeatherAlarmData) -> str:
        """æ ¼å¼åŒ–æ°”è±¡é¢„è­¦æ¶ˆæ¯"""
        lines = ["â›ˆï¸ã€æ°”è±¡é¢„è­¦ã€‘"]

        # æ ‡é¢˜
        if weather.headline:
            lines.append(f"ğŸ“‹{weather.headline}")

        # æè¿°
        if weather.description:
            # é™åˆ¶æè¿°é•¿åº¦
            desc = weather.description
            if len(desc) > 384:
                desc = desc[:384] + "..."
            lines.append(f"ğŸ“{desc}")

        # ç”Ÿæ•ˆæ—¶é—´ - æ·»åŠ æ—¶åŒºä¿¡æ¯
        if weather.effective_time:
            timezone = MessageFormatter._get_source_timezone(weather.source)
            lines.append(
                f"â°ç”Ÿæ•ˆï¼š{weather.effective_time.strftime('%Y-%m-%d %H:%M')} ({timezone})"
            )

        return "\n".join(lines)
